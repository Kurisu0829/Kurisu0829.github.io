---
title: 计网八股
date: 2024-07-16 15:17:00 +0800
categories: [学习, 八股]
tags: [八股]
---

主要做一个大纲，尽量口语化供日后复习检验，详细内容还是在小林Coding上查看。

## 一. TCP/IP网络模型和OSI网络模型
### TCP/IP模型
1. 应用层  
* 用户直接接触到的层次，提供网络与应用交互的接口，通过各种应用层协议为应用提供服务，比如HTTP、FTP、SMTP。
2. 传输层  
* 为应用层提供网络支撑，承接着应用层数据的收发。
* 有TCP、UDP两个协议，TCP相比UDP更加可靠，提供了流量控制、超时重传、拥塞控制等功能，而UDP只负责数据发出，不保证是否能抵达目标方，当然效率会因此变高。
3. 网络层  
* 使用IP对设备进行编号，通过IP寻址找到目标设备，通过路由找到前往目标的路径。
4. 网络接口层  
* 网络接口层主要为网络层提供「链路级别」传输的服务，IP无法在以太网中识别设备，因此需要MAC地址标识设备，通过ARP等协议由IP获取目标MAC地址，实现数据在以太网的传输。

### OSI模型
1. 应用层
* 网络与应用交互的接口，通过各种应用层协议为应用提供网络服务。
2. 表示层
* 负责数据格式的转换以及加密解密，确保数据的正确解释和呈现。
3. 会话层
* 负责管理应⽤程序之间的会话连接，包括创建、维护以及终止。（应用层+表示层+会话层与TCP/IP模型的应用层相似）
4. 传输层
* 提供应用到应用的数据传输服务，承接应用层数据的收发。（与TCP/IP模型的传输层相似）
5. 网络层
* 负责数据的路由和转发。（与TCP/IP模型的网络层相似）
6. 数据链路层
* 建⽴逻辑连接、进⾏硬件地址寻址、差错校验等功能，以MAC地址访问介质。
7. 物理层
* 负责物理传输媒介的传输，进行电信号和数字信号之间的转换。（数据链路层+物理层与TCP/IP模型的网络接口层相似）

## 二. 从输入URL到页面显示经历了什么
### HTTP
1. 解析URL，URL组成为：协议//Web服务器/目录名/...... /文件名，比如https://bilibili.com/blackborad/activity-list.html
2. 根据解析出来的信息生成HTTP请求信息。

### DNS
1. 域名的层级关系  
* 根DNS服务器（.）
* 顶级域DNS服务器（.com）
* 权威DNS服务器（server.com）
2. 域名解析流程  
* 询问本地DNS服务器，查询缓存。
* 询问根DNS服务器，根DNS服务器给出.com的地址。
* 询问.com顶级域DNS服务器，顶级域DNS服务器给出server.com权威DNS服务器的地址。
* 询问server.com权威DNS服务器，给出目标IP。
3. 迭代查询和递归查询
* 迭代查询里，客户端向上层DNS服务器发起查询请求，其只是询问一个更高级的DNS服务器的地址，再向该更高级服务器发起请求，直到获取完整的解析结果。
* 递归查询，客户端向上层DNS服务器发起查询请求，等待服务器返回完整结果，上层服务器会自动查询下一级服务器，并最终返回结果。

### 协议栈
1. 应用程序通过Socket库，委托操作系统中的协议栈工作。
2. 协议栈上半是负责收发数据的TCP和UDP协议，下半是控制网络包收发的IP协议，再由网卡驱动控制网卡完成链路层面的收发。

### TCP
1. 由于HTTP是基于TCP传输的，于是应用程序会委托操作系统调用协议栈中的TCP协议。
2. 在HTTP使用TCP传输数据前，首先需要通过三次握手建立连接，保证双方都有发送和接收的能力。   
3. 若HTTP请求消息过长，需要分割数据。  
4. 根据TCP包头结构需要，加上TCP头部，生成TCP报文，内容涉及源端口号和目标端口号、包的序号、确认号、状态位、窗口大小。  

### IP
1. TCP模块在执行连接、收发、断开等各阶段操作时，都需要委托IP模块将数据封装成网络包发送给通信对象。
2. 根据IP包头格式，加上IP头部，生成IP报文，内容涉及源地址IP和目标地址IP、上层传输协议号。
3. 存在多块网卡需要根据路由表判断源地址IP是哪一个网卡的。  

### MAC
1. MAC地址是以太网使用的头部，前面网络分层模型有提到过。
2. 确认发送方接收方，通过ARP协议获取接收方的MAC地址。
3. 加上MAC头部，生成MAC报文，内容包括接收方MAC地址、发送方MAC地址、协议类型。

### 网卡
1. 负责数字信号和电信号之间的转换。
2. 网卡驱动获取网络包之后，会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列，转换为电信号发出去。

### 交换机
1. 交换机接收数据包，将电信号变为数字信号，一般来说收到包的设备会核对包头的接收方MAC地址是否为自己，不是则丢弃，但对于交换机来讲他本身没有MAC地址，他会去查询MAC地址表，发送包到对应端口上。
2. MAC不存在则会转发到除了源端口的所有端口上，并在MAC地址表上进行记录。

### 路由器
1. 路由器与交换机不同的是，路由器各个端口都是有MAC地址和IP地址的，其可以作为包的发送方和接收方。
2. 路由器会接受发送给自己的包，丢弃MAC地址不匹配的包。
3. 路由表接收包后，去除MAC头部，路由器会根据后方的IP头部中的内容，查询路由表确定转发目标
4. 是否到达终点以路由表网关为准，如果网关是一个IP地址，则还未抵达终点，还需继续需要路由器转发。如果网关为空，也是就终于找到IP包头里的目标地址了，说明已抵达终点。会继续通过ARP协议根据IP查询MAC地址，再通过端口发送出去，层层转发。

### 服务器与客户端
1. 服务器收到报文，扒开MAC头部，检查是否和自己的MAC地址相符。
2. 扒开IP头部，发现IP地址相符，上层协议是TCP。
3. 扒开TCP头部，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个ACK。TCP头部里面还有端口号，HTTP的服务器正在监听这个端口号。
4. 于是服务器将网页内容封装在HTTP响应报文中，以同样的流程发送回客户端。
5. 客户端收到报文也开始扒开头部，把收到的数据包的皮扒剩HTTP响应报文后，交给浏览器去渲染页面，网页就显示出来了。
6. 四次挥手断开TCP连接。

## 三. HTTP请求报文和响应报文是怎样的
### 请求报文
其主要由请求⾏、请求头、请求体构成。
1. 请求行
* 请求⽅法： GET、POST、PUT、DELETE、PATCH、HEAD、OPTIONS、TRACE
* URL： <协议>：//<主机>：<端⼝>/<路径>?<参数>
* 协议版本号： HTTP版本号
2. 请求头  
包含请求的附加信息：
* Host：指定服务器的主机名和端⼝号。
* User-Agent：标识客户端的⽤户代理（浏览器或其他⼯具）。
* Accept：指定客户端可以接受的响应的MIME类型。
* Content-Type：指定请求主体的MIME类型。
* Authorization：⽤于进⾏身份验证的凭据。
3. 请求体
* 承载多个请求参数的数据, 请求体是可选的，通常在发送POST、PUT等请求时包含请求的实际数据。

### 响应报文
HTTP响应报⽂是服务器向客户端返回的数据格式，通常包含状态⾏、响应头、响应体。
1. 状态行
* HTTP协议版本（通常是"HTTP/1.1"）
* 状态码（表示服务器处理结果的三位数字代码）
* 状态消息（对状态码的简要描述）
2. 响应头
* Content-Type：指定响应主体的MIME类型。
* Content-Length：指定响应主体的⻓度（字节数）。
* Server：指定服务器的信息。
* Location：在重定向时指定新的资源位置。
* Set-Cookie：在响应中设置Cookie。
3. 响应体
* 响应主体包含服务器返回给客户端的实际数据。

## 四. HTTP请求方式有哪些
1. GET：申请获取资源，不对服务器产⽣影响。
2. POST：POST请求通常⽤于发送数据，例如提交表单数据、上传⽂件等，会影响服务器，服务器可能动态创建新的资源或更新原有资源。
3. HEAD：类似GET，仅要求服务器返回头部信息，不返回实际的资源内容。
4. PUT：⽤于更新服务器上的资源或创建新资源。
5. DELETE：请求服务器删除指定的资源。
6. TRACE：⽤于测试。要求⽬标服务器返回原始的HTTP请求内容。
7. PATCH： ⽤于对资源进⾏部分更新。
8. CONNECT：⽤于代理服务器。
9. OPTIONS：⽤于获取服务器⽀持的HTTP⽅法列表，以及针对指定资源⽀持的⽅法。

## 五. GET请求和POST请求有哪些区别
1. 语义
* 按照规范，GET的语义是从服务器获取指定资源。
* 按照规范，POST的语义是根据请求负荷（报文body）对指定的资源做出处理。
* 两种请求一个不会对服务器资源做出修改，一个会对服务器资源作出修改。
2. 参数
* 按照规范，GET请求的参数位置一般是写在URL中，URL规定只能支持ASCII，所以GET请求的参数只允许ASCII字符 ，而且浏览器会对URL的长度有限制。
* POST请求携带数据的位置一般是写在报文body中，body中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对body大小做限制。
* 但实际上任何请求都可以带body，POST请求的URL中也可以有参数，只是按照规范定义来讲是不行的。

## 六. HTTP常见状态码
1. 1xx：提示信息，表示正在HTTP请求处理的中间态。
2. 2xx：服务器成功处理了客户端的请求。如200、204、206
3. 3xx：客户端请求的资源发生了变动，重定向。如301、302、304
4. 4xx：服务端无法处理客户端发送的报文。如400、403、404
5. 5xx：客户端报文正确，服务器处理时内部出现了问题。如500、501、502、503

## 七. 什么是强制缓存和协商缓存
### 强制缓存
1. 概念：只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存。
2. 实现方式：通过响应头部的Cache-Control或是Expires字段来实现，区别在于前者是相对时间，后者是绝对时间，Cache-Control的优先级高于Expires，选项设置更加精细多样。

### 协商缓存
协商缓存是在Cache-Control已过期的情况下才考虑的。
1. 概念：通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存，即使Cache-Control已过期，服务器告诉客户端你可以继续使用这个缓存。
2. 实现方式：
* 请求头部中的If-Modified-Since字段与响应头部中的Last-Modified字段实现，响应头部返回Last-Modified即资源最后被修改的时间，缓存过期后下一次发出请求时在头部If-Modified-Since字段带上该时间，与服务器资源现在的最后被修改时间进行比较，若服务器资源较新，返回最新资源，反之则走304状态码继续使用缓存。
* 请求头部中的If-None-Match字段与响应头部中的ETag字段实现，当资源过期时，浏览器发现响应头里有Etag，则再次向服务器发起请求时，会将请求头If-None-Match值设置为Etag的值。服务器收到请求后进行比对，如果资源没有变化返回304，如果资源变化了返回200。

## 八. HTTP1.0和HTTP1.1区别
1. HTTP1.1使用长连接的方式改善了HTTP1.0短连接造成的性能开销
2. 支持管道网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。
3. HTTP1.0主要使⽤If-Modified-Since/Expires来做为缓存判断的标准，HTTP1.1则引⼊了更多的缓存控制策略例如Etag / If-None-Match等更多可供选择的缓存头来控制缓存策略。
4. HTTP1.1增加了状态码。
5. HTTP1.1新增了Host字段，使得⼀个服务器能够⽤来创建多个Web站点。
6. HTTP1.0中，存在⼀些浪费带宽的现象，例如客户端只是需要某个对象的⼀部分，⽽服务器却将整个对象送过来了，并且不⽀持断点续传功能。HTTP1.1则在请求头引⼊了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content）

## 九. HTTP2.0和HTTP1.1区别
1. 头部压缩
* 对于 Body 部分，HTTP/1.1 协议就已经可以使用头字段指定 Body 的压缩方式，比如用 gzip 压缩，这样可以节约带宽。
* 对于Header部分，HTTP2.0开发了 HPACK 算法，客户端和服务器两端都会建立和维护静态表、动态表，用长度较小的索引号表示重复的字符串，再用 Huffman 编码压缩数据，可达到 50%~90% 的高压缩率。
* 静态表是固定的61组头部字段+字段值，动态表是动态维护的头部字段+字段值，使用时会用索引号来替代重复内容。Huffman编码就是根据字母使用频率设计的一套编码，常用的字母编码短，节省空间。
2. 二进制帧
* 由Frame Header + Frame Payload组成
* Frame Payload就是结果HPACK算法压缩的HTTP头部和包体，二进制帧配合HPACK算法便于数据的压缩，极大提高了HTTP传输效率，而且二进制数据使用位运算能高效解析。
3. 并发传输
* HTTP1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务才能处理下一个事务，造成了队头阻塞的问题。
* HTTP2.0通过 Stream 这个设计，多个 Stream 复用一条 TCP 连接，达到并发的效果，解决了 HTTP1.1 队头阻塞的问题，提高了 HTTP 传输的吞吐量。
* 多个 Stream 跑在一条 TCP 连接，同一个 HTTP 请求与响应是跑在同一个 Stream 中，HTTP 消息可以由多个 Frame 构成， 一个 Frame 可以由多个 TCP 报文构成。
* 在 HTTP2.0 连接上，不同 Stream 的帧是可以乱序发送的，帧的头部会携带 Stream ID 信息，接收端可以通过 Stream ID 有序组装成 HTTP 消息，而同一 Stream 内部的帧必须是严格有序的。
4. 服务器主动推送资源
* 客户端和服务器双方都可以建立 Stream，因为服务端可以主动推送资源给客户端， 客户端建立的 Stream ID 必须是奇数号，而服务器建立的 Stream ID 必须是偶数号。
* 客户端通过 HTTP1.1 请求从服务器那获取到了 HTML 文件，而 HTML 可能还需要依赖 CSS 来渲染页面，这时客户端还要再发起获取 CSS 文件的请求，需要两次消息往返。
* 通过HTTP2.0，服务器可以直接主动推送 CSS 文件，减少了消息传递的次数，这是通过Stream ID，客户端为奇数，服务端为偶数进行简单计算实现的。

## 十. HTTP3.0
1. UDP & QUIC
* HTTP2.0存在的问题基本都是TCP协议引起的，故直接弃用，选用UDP。
2. 无队头阻塞
* HTTP2.0只是针对请求-响应模型做出了优化，但若是遇到TCP 丢包，整个 TCP 仍然是都要等待重传，那么就会阻塞该 TCP 连接中的所有请求，发生队头阻塞。
* UDP不关心数据包的顺序和是否丢失，QUIC基于UDP，为每个数据包定义一个序号作为唯一标识，针对一个流，如果有数据包丢失，直到QUIC重传丢失的报文，数据不会被读取，而其他流不会受到影响。
3. 更快的连接建立
* 基于TCP的HTTP协议发起HTTP请求时，需要经过 TCP 三次握手和 TLS 四次握手共需要 3 个 RTT 的时延才能发出请求数据。
* HTTP3.0 的 QUIC 协议并不是与 TLS 分层，而是 QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS 1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。
4. 连接迁移
* 一个 TCP 连接是由四元组（源 IP 地址，源端口，目标 IP 地址，目标端口）确定的，这意味着如果 IP 地址或者端口变动了，就会导致需要 TCP 与 TLS 重新握手。
* QUIC 协议没有用四元组的方式来“绑定”连接，而是通过连接 ID 来标记通信的两个端点，因此即使IP地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。

## 十一. HTTP和HTTPS区别
1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
3. 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

## 十二. HTTPS工作原理
1. HTTPS主要是基于在HTTP和TCP之间加入的SSL/TLS协议工作的，其通过混合加密、摘要算法与数字签名、数字证书解决了HTTP的窃听、篡改、冒充风险。
2. SSL/TLS协议基本流程
* 客户端向服务器索要并验证服务器的公钥。
* 双方协商生产「会话秘钥」。
* 双方采用「会话秘钥」进行加密通信。
3. 流程前两步就是连接的建立，也就是SSL/TLS四次握手阶段。
* RSA算法为例：首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello。客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性，通过这三步的随机数生成本次通信的「会话秘钥」。服务器收到客户端的第三个随机数之后，计算出本次通信的「会话秘钥」，然后，向客户端发送最后的信息。
4. TLS 在实现上分为握手协议和记录协议两层，通过记录协议保证数据完整性，记录协议完成后，最终的报文数据将传递到传输控制协议 (TCP) 层进行传输，流程如下：
* 首先，消息被分割成多个较短的片段,然后分别对每个片段进行压缩。
* 接下来，经过压缩的片段会被加上消息认证码（MAC 值，这个是通过哈希算法生成的），这是为了保证完整性，并进行数据的认证。通过附加消息认证码的 MAC 值，可以识别出篡改。与此同时，为了防止重放攻击，在计算消息认证码时，还加上了片段的编码。
* 再接下来，经过压缩的片段再加上消息认证码会一起通过对称密码进行加密。
* 最后，上述经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。  

## 十三. TCP和UDP的区别
1. TCP是⾯向连接的，在传输前需要三次握⼿建⽴连接；UDP不需要连接，直接发送数据包，没有连接建⽴和关闭的过程。
2. TCP是⼀对⼀的通信；UDP可以是⼀对⼀、⼀对多或多对多的通信。
3. TCP保证数据可靠交付，拥有确认应答和重传机制，⽆重复、不丢失、按序到达；UDP发送数据后不会关⼼数据包是否成功到达接收⽅，不会进⾏重传，不保证可靠性.
4. TCP拥有流量控制、拥塞控制，确保数据发送的速率不会超过接收⽅的处理能⼒，防止网络拥塞；UDP不进⾏流量控制和拥塞控制，数据发送的速率不受限制。
5. TCP的⾸部⼤⼩通常为20字节，但在选项字段被使⽤的情况下，可能会更⼤，TCP⾸部包含源端⼝号、⽬标端⼝号、序列号、确认号、窗⼝⼤⼩、校验和等字段；UDP的⾸部⼤⼩固定为8字节，UDP⾸部包含源端⼝号、⽬标端⼝号、包⻓度和校验和字段（各16位）
6. TCP基于字节流，没有边界，但是保证传输顺序和可靠性;UDP继承了IP层特性，基于数据包，有边界可能出现乱序和丢包。 
7. TCP数据⼤于MSS时会在TCP层将数据进⾏分⽚传输，到达⽬的地后同样在传输层进⾏合并，如果有某个⽚丢失则只需要重传丢失的分⽚即可;UDP数据⼤于MTU时会在IP层分⽚，则会在IP层合并，如果某个IP分⽚丢失，⽬标主机收到后，在 IP 层组装完数据，接着再传给传输层。

## 十四. TCP如何确保连接可靠性
### 重传机制
1. 超时重传
* 在发送数据时，设置一个定时器，当超过指定时间后没有收到对方的ACK确认应答报文，就会重发该数据，会在数据包丢失以及确认应答丢失这两种情况下出现。
* 超时时间的设置有讲究，RTT往返时延指的是数据发送时刻到接收到确认的时刻的差值。RTO太过大于RTT，重发就慢，丢了老半天才重发，没有效率，性能差；RTO太过小于RTT，重发就快，会增加网络拥塞，导致更多的超时。综上，超时重传时间 RTO 的值应该略大于报文往返 RTT 的值
2. 快速重传
* 快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。
* 存在重传的时候，是重传一个，还是重传所有的问题。
3. SACK
* 在TCP 头部「选项」字段里加一个 SACK 的东西，它可以将已收到的数据信息发送给发送方，发送方就知道对方收到那些信息了，知道这些信息就可以只重传丢失的数据了。
4. D-SACK
* 使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。
* 在ACK丢包以及网络延迟中可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;可以知道是不是「发送方」的数据包被网络延迟了;可以知道网络中是不是把「发送方」的数据包给复制了。

### 滑动窗口
* 窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值，即使在往返时间较长的情况下，它也不会降低网络通信的效率。
* 窗口实际上是操作系统开辟的一个缓存空间，发送方在确认应答返回前，要在缓冲区保留发送的数据，若按期收到回复，数据就可以从缓冲区删除。
* TCP 头里有一个字段叫 Window，也就是窗口大小，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据的，于是发送端就可以根据这个接收端的处理能力来发送数据，所以，通常窗口的大小是由接收方的窗口大小来决定的。
1. 发送窗口
* 分为已发送并收到 ACK确认的数据、已发送但未收到 ACK确认的数据、未发送但总大小在接收方处理范围内的数据、未发送但总大小超过接收方处理范围的数据四个部分。已发送但未收到ACK确认的数据 + 未发送但总大小在接收方处理范围内的数据就是窗口大小。
2. 接收窗口
* 分为已成功接收并确认的数据、未收到数据但可以接收的数据、未收到数据并不可以接收的数据三个部分。
* 接收窗口的大小是约等于发送窗口的大小的。

### 流量控制
1. 操作系统缓冲区
* 当应用程序没有及时读取缓存时，操作系统会影响发送窗口和接收窗口的变化。
* 当服务端系统资源非常紧张的时候，操作系统可能会直接减少了接收缓冲区大小，这时应用程序又无法及时读取缓存数据，会出现数据包丢失的现象。表现为窗口右端向左回缩，可用窗口大小出现负值。
* 为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。
2. 窗口关闭
* 如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。
* 会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，产生死锁。
* TCP 为每个连接设有一个持续定时器，只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。持续计时器超时，就会发送窗口探测报文，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。打破死锁
3. 糊涂窗口综合症
* 接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。TCP + IP 头有 40 个字节，当窗口特别小的时候，开销不值得。
* 我们可以让让接收方不通告小窗口给发送方、让发送方避免发送小数据来解决。
* 接收方通常的策略是当「窗口大小」小于 MSS 与 1/2 缓存大小中的最小值时，会向发送方通告窗口为 0，也就阻止了发送方再发数据过来。
* 发送方通常的策略是使用 Nagle 算法只有满足下面两个条件中的任意一个条件，才可以发送数据：要等到窗口大小 >= MSS 并且 数据大小 >= MSS；收到之前发送数据的 ack 回包。只要上面两个条件都不满足，发送方一直在囤积数据，直到满足上面的发送条件。

### 拥塞控制
拥塞控制，控制的目的是避免「发送方」的数据填满整个网络。拥塞窗口 cwnd是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络出现了拥塞。
1. 慢启动
* TCP 在刚建立连接完成后，首先是有个慢启动的过程，就是一点一点的提高发送数据包的数量。
* 当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。
* 当 cwnd < ssthresh（慢启动门限） 时，使用慢启动算法；当 cwnd >= ssthresh 时，就会使用「拥塞避免算法」。
2. 拥塞避免
* 每当收到一个 ACK 时，cwnd 增加 1/cwnd。
3. 拥塞发生
* 发生了「超时重传」，则就会使用拥塞发生算法，ssthresh 设为 cwnd/2，cwnd 重置为 1。较为激进，容易造成网络卡顿。
* 发生了「快速重传」，则会发生cwnd = cwnd/2 ，也就是设置为原来的一半；ssthresh = cwnd；并进入快速恢复算法。
4. 快速恢复
* 快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 RTO 超时那么强烈。
* 进入该算法后，拥塞窗口 cwnd = ssthresh + 3；重传丢失的数据包；如果再收到重复的 ACK，那么 cwnd 增加 1；如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值。
* 最后是因为该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态。

## 十五. UDP怎么实现可靠传输
其实就是把TCP的可靠传输特性在UDP也实现一遍，包括序列号、确认应答、超时重传、流量控制、拥塞控制等。
1. 协议的头部字段
* QUIC对UDP头部进行了改进，在UDP头部和HTTP消息中加入了Packet Header + QUIC Frame Header + HTTP3 Frame Header三层。
* QUIC 也是需要三次握手来建立连接的，主要目的是为了协商连接 ID。协商出连接 ID 后，后续传输时，双方只需要固定住连接 ID，Long Packet Header 用于首次建立连接；Short Packet Header 用于日常传输数据，也就是说后续Short Packet Header就只需要传输连接ID就行。
* 消除TCP 重传的歧义问题，Packet Header中的Packet Number严格递增，可以判断出是「原始报文的响应」还是「重传报文的响应」，便于精准测量RTT。
* QUIC 通过单向递增的 Packet Number，配合QUIC Frame Header中的 Stream ID 与 Offset 字段信息实现有序性，丢失的数据包和重传的数据包 Stream ID 与 Offset 都一致，说明这两个数据包的内容一致。可以支持乱序确认而不影响数据包的正确组装。
2. 队头阻塞
* HTTP/2 多个 Stream 请求都是在一条 TCP 连接上传输，这意味着多个 Stream 共用同一个 TCP 滑动窗口，那么当发生数据丢失，滑动窗口是无法往前移动的，这是TCP的问题。
* QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口。
3. 流量控制
* TCP 流量控制是通过让「接收方」告诉「发送方」，它（接收方）的接收窗口有多大，从而让「发送方」根据「接收方」的实际接收能力控制发送的数据量。
* QUIC通过 window_update 帧告诉对端自己可以接收的字节数，这样发送方就不会发送超过这个数量的数据；通过 BlockFrame 告诉对端由于流量控制被阻塞了，无法发送数据。
* 每条Stream独立滑动窗口。
4. 连接建立
* 参考HTTP3.0的连接建立部分。
5. 迁移连接 
* 参考HTTP3.0的连接迁移部分。

## 十六. 三次握手过程 & 为什么是三次？
1. 三次握手过程
* 一开始，客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。
* 客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，之后客户端处于 SYN-SENT 状态。
* 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号，将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。之后服务端处于 SYN-RCVD 状态。
* 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，客户端收到服务端报文后，还要向服务端回应最后一个应答报文，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ESTABLISHED 状态。
* 从上面的过程可以发现第三次握手是可以携带数据的，前两次握手是不可以携带数据的
2. 为什么是三次？
* 因为三次握手才能保证双方具有接收和发送的能力（片面），重要的是为什么三次握手才可以初始化 Socket、序列号和窗口大小并建立 TCP 连接
* 三次握手才可以阻止重复历史连接的初始化（主要原因）
* 三次握手才可以同步双方的初始序列号
* 三次握手才可以避免资源浪费

## 十七. 四次挥手过程 & 为什么是四次？
1. 四次握手过程
* 客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。
* 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSE_WAIT 状态。
* 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。
* 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。
* 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态。
* 服务端收到了 ACK 应答报文后，就进入了 CLOSE 状态，至此服务端已经完成连接的关闭。
* 客户端在经过 2MSL 一段时间后，自动进入 CLOSE 状态，至此客户端也完成连接的关闭。
2. 为什么是四次？
* 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。
* 服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，
* 服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，因此是需要四次挥手。

## 十八. HTTP的Keep-Alive是什么？它和TCP的Keepalive是一个东西吗？
1. HTTP 的 Keep-Alive 是实现了长连接功能，是由应用层（用户态） 实现的。
2. TCP 的 Keepalive 是 TCP 的保活机制，是由 TCP 层（内核态） 实现的。如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。对端会正常响应，这样 TCP 保活时间会被重置，未响应达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。

## 十九. CDN是什么
### CDN概念
1. CDN，全称为内容分发⽹络 （Content Delivery Network） , 过将内容存储在分布式的服务器上，使⽤户可以从距离较近的服务器获取所需的内容，从⽽减少数据传输的时间和距离，提⾼内容的传输速度、减少延迟和提升⽤户体验。

### CND工作流程
1. 当⽤户输⼊⼀个域名或点击⼀个链接时，⾸先会进⾏域名解析。如果⽹站启⽤了 CDN，DNS 解析会返回距离⽤户最近的 CDN 节点的 IP 地址，⽽不是原始源服务器的 IP 地址。
2. ⽤户的请求会被路由到距离最近的 CDN 节点，并且CDN 节点可以根据服务器的负载和可⽤性，动态地将请求分发到最适合的服务器节点上。
3. CDN 会⾸先检查是否已经缓存了该资源。如果有缓存，CDN 节点会直接返回缓存的资源，如果没有缓存所需资源，它会从源服务器（原始服务器）回源获取资源，并将资源缓存到节点中，以便以后的请求。

### CDN是如何加速的
1. 就近访问：CDN 在全球范围内部署了多个服务器节点，当⽤户请求访问⼀个⽹站时，CDN 会选择距离⽤户最近的节点来提供内容。这减少了数据传输的距离和时间，从⽽降低了延迟。
2. 内容缓存：CDN 节点会缓存静态资源，如图⽚、样式表、脚本等。当⽤户请求访问这些资源时，CDN 可以直接从缓存中返回，避免了从源服务器获取资源的延迟。
3. 前置缓存：CDN 可以根据⽹站的配置，提前将热⻔的内容缓存在节点中，以备⽤户请求时快速响应。
4. 智能负载均衡：CDN 会根据服务器的负载和可⽤性，动态地将请求分发到合适的服务器节点上，确保资源的快速获取。
5. 压缩技术：CDN 使⽤压缩技术对内容进⾏压缩，减少传输数据的⼤⼩，从⽽加快内容的传输速度。
6. 并⾏下载：由于 CDN ⽀持多路复⽤，⽤户可以在同⼀个连接上同时下载多个资源，从⽽提⾼并⾏下载的效率。

## 二十. Cookie和Session是什么，有什么区别
Cookie 和 Session 都⽤于管理⽤户的状态和身份, Cookie 通过在客户端记录信息确定⽤户身份， Session 通过在服务器端记录信息确定⽤户身份。

### Cookie
1. Cookie 是存储在⽤户浏览器中的⼩型⽂本⽂件，⽤于在⽤户和服务器之间传递数据。通常，服务器会将⼀个或多个 Cookie 发送到⽤户浏览器，然后浏览器将这些 Cookie 存储在本地。
2. 服务器在接收到来⾃客户端浏览器的请求之后，就能够通过分析存放于请求头的Cookie得到客户端特有的信息，从⽽动态⽣成与该客户端相对应的内容。
3. 通过服务器在 HTTP 响应中设置 "Set-Cookie" 标头，然后浏览器将这些 Cookie 存储并在后续的请求中发送给服务器。这样服务器可以通过 Cookie 实现⽤户状态管理和数据传递。

### Session
1. 客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是 Session。Session主要⽤于维护⽤户登录状态、存储⽤户的临时数据和上下⽂信息等。
2. ⽤户⾸次访问⽹站时，服务器会为该⽤户创建⼀个唯⼀的会话标识符（Session ID）。这个标识符可以是⼀个加密的字符串，通常以 Cookie 的形式存储在⽤户的浏览器中。
3. 每个会话标识符对应着服务器上的⼀个会话存储空间。这个存储空间⽤于存储该⽤户在会话期间的状态和数据。
4. 当⽤户与服务器交互时，服务器可以通过会话标识符来访问对应的会话存储空间。服务器可以将数据存储在会话中，如⽤户的登录状态、购物⻋内容、⽤户偏好等。
5. 服务器为每个会话设置⼀个超时时间，如果⽤户在⼀段时间内没有活动，会话会⾃动过期。⼀旦会话过期，会话数据将被清除。
6. ⽤户可以⼿动终⽌会话，例如通过退出登录操作。这会导致服务器删除与该⽤户相关的会话数据。

一般来讲Cookie 存储容量较⼩，⼀般为⼏ KB。Session 存储容量较⼤，通常没有固定限制，取决于服务器的配置和资源。同时，由于 Cookie 存储在⽤户浏览器中，因此可以被⽤户读取和篡改。相⽐之下，Session 数据存储在服务器上，更难被⽤户访问和修改。Cookie 在每次 HTTP 请求中都会被⾃动发送到服务器，⽽ Session ID 通常通过 Cookie 或 URL 参数传递。